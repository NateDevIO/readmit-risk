{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospital & Geographic Analytics\n",
    "\n",
    "**Objective**: Analyze CMS hospital data for geographic patterns and provider performance.\n",
    "\n",
    "This notebook processes CMS Hospital Readmissions Reduction Program data to create state-level summaries and hospital metrics for the geographic analysis dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set up paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "OUTPUT_DIR = Path('../data/processed')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load CMS Hospital Readmissions Data\n",
    "df_hosp = pd.read_csv(DATA_DIR / 'hospital_readmissions.csv')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CMS HOSPITAL READMISSIONS DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataset shape: {df_hosp.shape}\")\n",
    "print(f\"\\nColumn names:\")\n",
    "for i, col in enumerate(df_hosp.columns):\n",
    "    print(f\"  {i+1}. {col}\")\n",
    "print(f\"\\nFirst 3 rows:\")\n",
    "df_hosp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Identify and Map Column Names\n",
    "# The CMS data columns vary by download - let's detect what we have\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COLUMN DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Common column name variations in CMS data\n",
    "column_mappings = {\n",
    "    # Hospital name variations\n",
    "    'hospital_name': ['Facility Name', 'Hospital Name', 'facility_name', 'hospital_name', 'Provider Name'],\n",
    "    # State variations\n",
    "    'state': ['State', 'state', 'Provider State', 'provider_state'],\n",
    "    # City variations\n",
    "    'city': ['City', 'city', 'Provider City', 'provider_city'],\n",
    "    # Rate/score variations\n",
    "    'readmission_rate': ['Score', 'Excess Readmission Ratio', 'Expected Readmission Rate', \n",
    "                         'excess_readmission_ratio', 'Predicted Readmission Rate'],\n",
    "    # Penalty variations\n",
    "    'penalty_pct': ['Payment Reduction Percentage', 'payment_reduction_percentage', \n",
    "                    'FY 2025 Payment Reduction Percentage'],\n",
    "    # Patient count variations\n",
    "    'patient_count': ['Number of Patients', 'number_of_patients', 'Discharges']\n",
    "}\n",
    "\n",
    "# Detect actual columns\n",
    "detected_columns = {}\n",
    "for target, possible_names in column_mappings.items():\n",
    "    for name in possible_names:\n",
    "        if name in df_hosp.columns:\n",
    "            detected_columns[target] = name\n",
    "            break\n",
    "\n",
    "print(\"\\nDetected column mappings:\")\n",
    "for target, actual in detected_columns.items():\n",
    "    print(f\"  {target} -> '{actual}'\")\n",
    "\n",
    "# Create standardized column names\n",
    "for target, actual in detected_columns.items():\n",
    "    if actual in df_hosp.columns:\n",
    "        df_hosp[target] = df_hosp[actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Data Cleaning\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA CLEANING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert numeric columns (handle 'Not Available' type values)\n",
    "if 'readmission_rate' in df_hosp.columns:\n",
    "    df_hosp['readmission_rate'] = pd.to_numeric(df_hosp['readmission_rate'], errors='coerce')\n",
    "    print(f\"readmission_rate: {df_hosp['readmission_rate'].notna().sum()} valid values\")\n",
    "\n",
    "if 'penalty_pct' in df_hosp.columns:\n",
    "    df_hosp['penalty_pct'] = pd.to_numeric(df_hosp['penalty_pct'], errors='coerce')\n",
    "    print(f\"penalty_pct: {df_hosp['penalty_pct'].notna().sum()} valid values\")\n",
    "\n",
    "if 'patient_count' in df_hosp.columns:\n",
    "    df_hosp['patient_count'] = pd.to_numeric(df_hosp['patient_count'], errors='coerce')\n",
    "\n",
    "# Drop rows without state\n",
    "if 'state' in df_hosp.columns:\n",
    "    df_hosp = df_hosp.dropna(subset=['state'])\n",
    "    print(f\"\\nHospitals with valid state: {len(df_hosp)}\")\n",
    "\n",
    "# For the rate column, if we have excess ratio instead of rate, convert it\n",
    "# Excess ratio of 1.0 = expected rate, >1.0 = higher than expected\n",
    "if 'readmission_rate' in df_hosp.columns:\n",
    "    rate_stats = df_hosp['readmission_rate'].describe()\n",
    "    print(f\"\\nReadmission rate statistics:\")\n",
    "    print(rate_stats)\n",
    "    \n",
    "    # If values are around 1.0, it's likely an excess ratio - convert to percentage\n",
    "    if rate_stats['mean'] < 5:\n",
    "        print(\"\\nDetected excess ratio format - converting to percentage\")\n",
    "        df_hosp['readmission_rate'] = df_hosp['readmission_rate'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: State-Level Aggregation\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATE-LEVEL AGGREGATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Determine which columns we have for aggregation\n",
    "agg_dict = {'hospital_name': 'count'}  # Count hospitals per state\n",
    "\n",
    "if 'readmission_rate' in df_hosp.columns and df_hosp['readmission_rate'].notna().any():\n",
    "    agg_dict['readmission_rate'] = 'mean'\n",
    "    rate_col = 'readmission_rate'\n",
    "else:\n",
    "    rate_col = None\n",
    "\n",
    "if 'penalty_pct' in df_hosp.columns and df_hosp['penalty_pct'].notna().any():\n",
    "    agg_dict['penalty_pct'] = 'mean'\n",
    "\n",
    "# Aggregate by state\n",
    "state_summary = df_hosp.groupby('state').agg(agg_dict).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "state_summary.columns = ['state'] + [\n",
    "    'hospital_count' if c == 'hospital_name' else \n",
    "    'avg_readmission_rate' if c == 'readmission_rate' else \n",
    "    'avg_penalty_pct' if c == 'penalty_pct' else c\n",
    "    for c in state_summary.columns[1:]\n",
    "]\n",
    "\n",
    "# Calculate estimated total penalty (using national average if available)\n",
    "AVG_MEDICARE_PAYMENTS_PER_HOSPITAL = 5000000  # $5M example\n",
    "if 'avg_penalty_pct' in state_summary.columns:\n",
    "    state_summary['total_penalty_estimate'] = (\n",
    "        state_summary['hospital_count'] * \n",
    "        AVG_MEDICARE_PAYMENTS_PER_HOSPITAL * \n",
    "        state_summary['avg_penalty_pct'] / 100\n",
    "    )\n",
    "else:\n",
    "    state_summary['total_penalty_estimate'] = 0\n",
    "\n",
    "# Sort by readmission rate if available\n",
    "if 'avg_readmission_rate' in state_summary.columns:\n",
    "    state_summary = state_summary.sort_values('avg_readmission_rate', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 10 states by readmission rate:\")\n",
    "print(state_summary.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\nBottom 10 states by readmission rate:\")\n",
    "print(state_summary.tail(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: State Coordinates for Map\n",
    "# US State coordinates for map visualization\n",
    "STATE_COORDS = {\n",
    "    'AL': {'lat': 32.806671, 'lng': -86.791130, 'name': 'Alabama'},\n",
    "    'AK': {'lat': 61.370716, 'lng': -152.404419, 'name': 'Alaska'},\n",
    "    'AZ': {'lat': 33.729759, 'lng': -111.431221, 'name': 'Arizona'},\n",
    "    'AR': {'lat': 34.969704, 'lng': -92.373123, 'name': 'Arkansas'},\n",
    "    'CA': {'lat': 36.116203, 'lng': -119.681564, 'name': 'California'},\n",
    "    'CO': {'lat': 39.059811, 'lng': -105.311104, 'name': 'Colorado'},\n",
    "    'CT': {'lat': 41.597782, 'lng': -72.755371, 'name': 'Connecticut'},\n",
    "    'DE': {'lat': 39.318523, 'lng': -75.507141, 'name': 'Delaware'},\n",
    "    'FL': {'lat': 27.766279, 'lng': -81.686783, 'name': 'Florida'},\n",
    "    'GA': {'lat': 33.040619, 'lng': -83.643074, 'name': 'Georgia'},\n",
    "    'HI': {'lat': 21.094318, 'lng': -157.498337, 'name': 'Hawaii'},\n",
    "    'ID': {'lat': 44.240459, 'lng': -114.478828, 'name': 'Idaho'},\n",
    "    'IL': {'lat': 40.349457, 'lng': -88.986137, 'name': 'Illinois'},\n",
    "    'IN': {'lat': 39.849426, 'lng': -86.258278, 'name': 'Indiana'},\n",
    "    'IA': {'lat': 42.011539, 'lng': -93.210526, 'name': 'Iowa'},\n",
    "    'KS': {'lat': 38.526600, 'lng': -96.726486, 'name': 'Kansas'},\n",
    "    'KY': {'lat': 37.668140, 'lng': -84.670067, 'name': 'Kentucky'},\n",
    "    'LA': {'lat': 31.169546, 'lng': -91.867805, 'name': 'Louisiana'},\n",
    "    'ME': {'lat': 44.693947, 'lng': -69.381927, 'name': 'Maine'},\n",
    "    'MD': {'lat': 39.063946, 'lng': -76.802101, 'name': 'Maryland'},\n",
    "    'MA': {'lat': 42.230171, 'lng': -71.530106, 'name': 'Massachusetts'},\n",
    "    'MI': {'lat': 43.326618, 'lng': -84.536095, 'name': 'Michigan'},\n",
    "    'MN': {'lat': 45.694454, 'lng': -93.900192, 'name': 'Minnesota'},\n",
    "    'MS': {'lat': 32.741646, 'lng': -89.678696, 'name': 'Mississippi'},\n",
    "    'MO': {'lat': 38.456085, 'lng': -92.288368, 'name': 'Missouri'},\n",
    "    'MT': {'lat': 46.921925, 'lng': -110.454353, 'name': 'Montana'},\n",
    "    'NE': {'lat': 41.125370, 'lng': -98.268082, 'name': 'Nebraska'},\n",
    "    'NV': {'lat': 38.313515, 'lng': -117.055374, 'name': 'Nevada'},\n",
    "    'NH': {'lat': 43.452492, 'lng': -71.563896, 'name': 'New Hampshire'},\n",
    "    'NJ': {'lat': 40.298904, 'lng': -74.521011, 'name': 'New Jersey'},\n",
    "    'NM': {'lat': 34.840515, 'lng': -106.248482, 'name': 'New Mexico'},\n",
    "    'NY': {'lat': 42.165726, 'lng': -74.948051, 'name': 'New York'},\n",
    "    'NC': {'lat': 35.630066, 'lng': -79.806419, 'name': 'North Carolina'},\n",
    "    'ND': {'lat': 47.528912, 'lng': -99.784012, 'name': 'North Dakota'},\n",
    "    'OH': {'lat': 40.388783, 'lng': -82.764915, 'name': 'Ohio'},\n",
    "    'OK': {'lat': 35.565342, 'lng': -96.928917, 'name': 'Oklahoma'},\n",
    "    'OR': {'lat': 44.572021, 'lng': -122.070938, 'name': 'Oregon'},\n",
    "    'PA': {'lat': 40.590752, 'lng': -77.209755, 'name': 'Pennsylvania'},\n",
    "    'RI': {'lat': 41.680893, 'lng': -71.511780, 'name': 'Rhode Island'},\n",
    "    'SC': {'lat': 33.856892, 'lng': -80.945007, 'name': 'South Carolina'},\n",
    "    'SD': {'lat': 44.299782, 'lng': -99.438828, 'name': 'South Dakota'},\n",
    "    'TN': {'lat': 35.747845, 'lng': -86.692345, 'name': 'Tennessee'},\n",
    "    'TX': {'lat': 31.054487, 'lng': -97.563461, 'name': 'Texas'},\n",
    "    'UT': {'lat': 40.150032, 'lng': -111.862434, 'name': 'Utah'},\n",
    "    'VT': {'lat': 44.045876, 'lng': -72.710686, 'name': 'Vermont'},\n",
    "    'VA': {'lat': 37.769337, 'lng': -78.169968, 'name': 'Virginia'},\n",
    "    'WA': {'lat': 47.400902, 'lng': -121.490494, 'name': 'Washington'},\n",
    "    'WV': {'lat': 38.491226, 'lng': -80.954453, 'name': 'West Virginia'},\n",
    "    'WI': {'lat': 44.268543, 'lng': -89.616508, 'name': 'Wisconsin'},\n",
    "    'WY': {'lat': 42.755966, 'lng': -107.302490, 'name': 'Wyoming'},\n",
    "    'DC': {'lat': 38.897438, 'lng': -77.026817, 'name': 'District of Columbia'},\n",
    "    'PR': {'lat': 18.220833, 'lng': -66.590149, 'name': 'Puerto Rico'},\n",
    "    'VI': {'lat': 18.335765, 'lng': -64.896335, 'name': 'Virgin Islands'},\n",
    "    'GU': {'lat': 13.444304, 'lng': 144.793731, 'name': 'Guam'}\n",
    "}\n",
    "\n",
    "print(f\"State coordinate database loaded: {len(STATE_COORDS)} states/territories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Export State Summary JSON\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPORTING STATE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Enrich state summary with coordinates\n",
    "state_data = []\n",
    "for _, row in state_summary.iterrows():\n",
    "    state_code = row['state']\n",
    "    coords = STATE_COORDS.get(state_code, {'lat': 0, 'lng': 0, 'name': state_code})\n",
    "    \n",
    "    state_entry = {\n",
    "        'state': state_code,\n",
    "        'name': coords['name'],\n",
    "        'lat': coords['lat'],\n",
    "        'lng': coords['lng'],\n",
    "        'hospital_count': int(row['hospital_count'])\n",
    "    }\n",
    "    \n",
    "    if 'avg_readmission_rate' in row:\n",
    "        state_entry['avg_readmission_rate'] = round(float(row['avg_readmission_rate']), 2)\n",
    "    else:\n",
    "        state_entry['avg_readmission_rate'] = 0\n",
    "        \n",
    "    state_entry['total_penalty_estimate'] = round(float(row.get('total_penalty_estimate', 0)), 0)\n",
    "    \n",
    "    state_data.append(state_entry)\n",
    "\n",
    "# Export to JSON\n",
    "with open(OUTPUT_DIR / 'state_summary.json', 'w') as f:\n",
    "    json.dump(state_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nExported state_summary.json ({len(state_data)} states)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Hospital-Level Export\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HOSPITAL-LEVEL EXPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Select top 500 hospitals by readmission rate for dashboard\n",
    "if 'readmission_rate' in df_hosp.columns:\n",
    "    df_hosp_clean = df_hosp.dropna(subset=['readmission_rate'])\n",
    "    df_top_hospitals = df_hosp_clean.nlargest(500, 'readmission_rate')\n",
    "else:\n",
    "    df_top_hospitals = df_hosp.head(500)\n",
    "\n",
    "# Prepare export\n",
    "hospital_data = []\n",
    "for _, row in df_top_hospitals.iterrows():\n",
    "    hospital_entry = {\n",
    "        'name': str(row.get('hospital_name', 'Unknown')),\n",
    "        'state': str(row.get('state', 'Unknown')),\n",
    "        'city': str(row.get('city', 'Unknown')) if pd.notna(row.get('city')) else 'Unknown',\n",
    "        'readmission_rate': float(row.get('readmission_rate', 0)) if pd.notna(row.get('readmission_rate')) else 0,\n",
    "        'penalty_pct': float(row.get('penalty_pct', 0)) if pd.notna(row.get('penalty_pct')) else 0\n",
    "    }\n",
    "    hospital_data.append(hospital_entry)\n",
    "\n",
    "# Export to JSON\n",
    "with open(OUTPUT_DIR / 'hospital_metrics.json', 'w') as f:\n",
    "    json.dump(hospital_data, f, indent=2)\n",
    "\n",
    "print(f\"Exported hospital_metrics.json ({len(hospital_data)} hospitals)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Verify All Exports\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION OF ALL EXPORTED FILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "export_files = [\n",
    "    OUTPUT_DIR / 'patient_risks.json',\n",
    "    OUTPUT_DIR / 'risk_summary.json', \n",
    "    OUTPUT_DIR / 'state_summary.json',\n",
    "    OUTPUT_DIR / 'hospital_metrics.json'\n",
    "]\n",
    "\n",
    "all_present = True\n",
    "for filepath in export_files:\n",
    "    if filepath.exists():\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, list):\n",
    "            print(f\"  {filepath.name}: {len(data)} records\")\n",
    "        else:\n",
    "            print(f\"  {filepath.name}: {len(data.keys())} keys\")\n",
    "    else:\n",
    "        print(f\"  {filepath.name}: FILE NOT FOUND\")\n",
    "        all_present = False\n",
    "\n",
    "if all_present:\n",
    "    print(\"\\n*** ALL DATA READY FOR DASHBOARD ***\")\n",
    "else:\n",
    "    print(\"\\n*** WARNING: Some files missing - run notebook 02 first ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Geographic Insights Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GEOGRAPHIC INSIGHTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'avg_readmission_rate' in state_summary.columns:\n",
    "    top_states = state_summary.nlargest(5, 'avg_readmission_rate')[['state', 'avg_readmission_rate', 'hospital_count']]\n",
    "    bottom_states = state_summary.nsmallest(5, 'avg_readmission_rate')[['state', 'avg_readmission_rate', 'hospital_count']]\n",
    "    \n",
    "    print(\"\\nHighest Readmission Rate States:\")\n",
    "    for _, row in top_states.iterrows():\n",
    "        state_name = STATE_COORDS.get(row['state'], {}).get('name', row['state'])\n",
    "        print(f\"  {state_name}: {row['avg_readmission_rate']:.1f}% ({row['hospital_count']} hospitals)\")\n",
    "    \n",
    "    print(\"\\nLowest Readmission Rate States:\")\n",
    "    for _, row in bottom_states.iterrows():\n",
    "        state_name = STATE_COORDS.get(row['state'], {}).get('name', row['state'])\n",
    "        print(f\"  {state_name}: {row['avg_readmission_rate']:.1f}% ({row['hospital_count']} hospitals)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Copy JSON files to dashboard:\n",
    "   cp ../data/processed/*.json ../dashboard/lib/\n",
    "\n",
    "2. Build Next.js dashboard:\n",
    "   cd ../dashboard\n",
    "   npm run dev\n",
    "\n",
    "3. Deploy to Vercel:\n",
    "   vercel --prod\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
